{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 1. Importing Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    "    StackingRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import (\n",
    "    ElasticNet,\n",
    "    Lasso,\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    Ridge,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 2. Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We read from the 04-encoded folder we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define paths (using pathlib for robustness)\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"04-encoded\"\n",
    "\n",
    "# 2. Load the datasets\n",
    "X_train = pd.read_csv(DATA_DIR / \"X_train_encoded.csv\")\n",
    "X_val = pd.read_csv(DATA_DIR / \"X_val_encoded.csv\")\n",
    "y_train = pd.read_csv(DATA_DIR / \"y_train.csv\").values.ravel()  # ravel() flattens it to an array\n",
    "y_val = pd.read_csv(DATA_DIR / \"y_val.csv\").values.ravel()\n",
    "\n",
    "print(f\"Data Loaded. X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Scaling The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### I\\. The Safety Check (Age Imputation)\n",
    "\n",
    "**Crucial:** If you didn't explicitly fill missing values in the Age column during your EDA/Feature Engineering phase, the Scaler will **crash**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Age has missing values\n",
    "if X_train[\"age\"].isnull().sum() > 0:\n",
    "    print(f\"Found {X_train['age'].isnull().sum()} missing ages. Filling with Median...\")\n",
    "\n",
    "    # Calculate median on TRAIN\n",
    "    age_median = X_train[\"age\"].median()\n",
    "\n",
    "    # Fill on all\n",
    "    X_train[\"age\"] = X_train[\"age\"].fillna(age_median)\n",
    "    X_val[\"age\"] = X_val[\"age\"].fillna(age_median)\n",
    "\n",
    "print(\"No missing values in Age.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### II\\. Scale & Save (The MLOps Step)\n",
    "\n",
    "We only scale the continuous columns (age, fare, FamilySize). We do **not** touch the binary columns (like sex\\_male, pclass\\_2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define columns to scale\n",
    "scale_cols = [\"age\", \"fare\", \"familysize\"]\n",
    "\n",
    "# 2. Initialize and Fit Scaler (On TRAIN only)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[scale_cols])\n",
    "\n",
    "# 3. Transform Data\n",
    "# We use .loc to modify the specific columns in place\n",
    "X_train.loc[:, scale_cols] = scaler.transform(X_train[scale_cols])\n",
    "X_val.loc[:, scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "\n",
    "# 4. Save the Scaler (CRITICAL for your API later)\n",
    "MODEL_DIR = PROJECT_ROOT / \"models\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "joblib.dump(scaler, MODEL_DIR / \"scaler.pkl\")\n",
    "# Save the list of columns that the model expects\n",
    "# This ensures we can align the API input perfectly later\n",
    "joblib.dump(X_train.columns.tolist(), \"../models/model_columns.pkl\")\n",
    "\n",
    "print(\"Model columns saved. We will use this to align the API input.\")\n",
    "\n",
    "print(f\"Data scaled and scaler saved to {MODEL_DIR}/scaler.pkl\")\n",
    "print(X_train[scale_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Model Tournament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "You don't want to just pick one model and hope for the best. You want to pit 4-5 different algorithms against each other, see which one learns the patterns best, and then \"promote\" the winner to the next round (Hyperparameter Tuning).\n",
    "\n",
    "### The \"Model Tournament\" Bracket\n",
    "\n",
    "1.  **The Qualifiers (Spot Checking):** We try 5-6 standard algorithms with their default settings. We don't tune them yet; we just want to see who has potential.\n",
    "    \n",
    "2.  **The Semi-Finals (Cross Validation):** We verify the scores aren't just \"luck\" from a specific train/test split.\n",
    "    \n",
    "3.  **The Finals (Hyperparameter Tuning):** We take the top 2 models and tweak their settings (the knobs and dials) to squeeze out every drop of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### The Setup (The Qualifiers)\n",
    "\n",
    "We will test these 6 classic competitors:\n",
    "\n",
    "1.  **Logistic Regression:** (Your Baseline - simple and interpretable).\n",
    "    \n",
    "2.  **K-Nearest Neighbors (KNN):** Looks for \"similar\" passengers.\n",
    "    \n",
    "3.  **Support Vector Machine (SVM):** Draws complex boundary lines.\n",
    "    \n",
    "4.  **Random Forest:** A team of Decision Trees voting together.\n",
    "    \n",
    "5.  **XGBoost:** The \"Kaggle King\" (Gradient Boosting).\n",
    "\n",
    "6. **MLPClassifier** Undisputed kings of Unstructured Data (Images, Audio, Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Models\n",
    "# NOTE: We added probability=True to SVM so it can give us percentages later!\n",
    "# Add it to your models dictionary\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    # The Neural Network Challenger\n",
    "    # max_iter=1000 gives it enough time to learn without giving up\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "}\n",
    "# 3. The Loop\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "print(\"üèÜ Running Model Tournament...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    # cv=5 means we test it 5 times on different chunks of data\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: {cv_scores.mean()*100:.2f}% Accuracy (+/- {cv_scores.std()*100:.2f}%)\")\n",
    "\n",
    "# 4. Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title(\"Model Comparison (Accuracy)\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Overall takeaway\n",
    "\n",
    "SVM and Random Forest show the **highest median accuracy**, while XGBoost has the **lowest median** and the most inconsistent performance. Logistic Regression and KNN are stable mid-performers, and the Neural Network is moderate but more variable.\n",
    "\n",
    "--------------------------------------------------\n",
    "### Model-by-model interpretation\n",
    "\n",
    "**SVM**\n",
    "\n",
    "*   Highest median accuracy (~0.84)\n",
    "    \n",
    "*   Relatively tight spreadüëâ Strong and consistent performer\n",
    "    \n",
    "\n",
    "**Random Forest**\n",
    "\n",
    "*   Similar median to SVM\n",
    "    \n",
    "*   Wider spread than SVMüëâ High peak performance but slightly less stable\n",
    "    \n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "*   Median around ~0.83\n",
    "    \n",
    "*   Small spreadüëâ Reliable and stable baseline model\n",
    "    \n",
    "\n",
    "**KNN**\n",
    "\n",
    "*   Slightly lower median (~0.82)\n",
    "    \n",
    "*   Fairly consistentüëâ Decent but not top-performing\n",
    "    \n",
    "\n",
    "**Neural Network**\n",
    "\n",
    "*   Moderate median (~0.82)\n",
    "    \n",
    "*   Noticeable variabilityüëâ Performance depends heavily on conditions\n",
    "    \n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "*   Lowest median (~0.79)\n",
    "    \n",
    "*   Wide spreadüëâ Most inconsistent and weakest performer in this comparison\n",
    "\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "### Variability insight\n",
    "\n",
    "*   Narrower boxes = more stable performance\n",
    "    \n",
    "*   Wider boxes/long whiskers = higher variability\n",
    "    \n",
    "*   Random Forest and XGBoost fluctuate more across runs\n",
    "    \n",
    "*   Logistic Regression and KNN are more predictable\n",
    "    \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "> SVM and Random Forest achieved the highest median accuracy, indicating superior predictive performance. Logistic Regression and KNN provided stable and competitive results with lower variance. The Neural Network showed moderate performance with some variability, while XGBoost had the lowest median accuracy and the widest spread, suggesting inconsistent behavior across runs. Overall, SVM appears to offer the best balance between accuracy and stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import all competitors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. SETUP: Define Models and their Hyperparameter Grids\n",
    "# -------------------------------------------------------------------------\n",
    "tournament_config = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"solver\": [\"liblinear\", \"lbfgs\"]},\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [5, 9, 15],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"p\": [1, 2],  # 1=Manhattan, 2=Euclidean\n",
    "        },\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        # Note: probability=True is needed for the final percentage output!\n",
    "        \"model\": SVC(probability=True, random_state=42),\n",
    "        \"params\": {\"C\": [1, 10, 100], \"kernel\": [\"rbf\", \"linear\"], \"gamma\": [\"scale\", \"auto\"]},\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [10, 20, None],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "        },\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"max_depth\": [3, 5, 7],\n",
    "        },\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        \"model\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
    "            \"activation\": [\"tanh\", \"relu\"],\n",
    "            \"alpha\": [0.0001, 0.05],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2. EXECUTION: The Loop\n",
    "# -------------------------------------------------------------------------\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "print(\"üèÜ STARTING MODEL TOURNAMENT...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, config in tournament_config.items():\n",
    "    print(f\"‚öôÔ∏è Tuning {name}...\")\n",
    "\n",
    "    # A. Grid Search (CV)\n",
    "    gs = GridSearchCV(\n",
    "        estimator=config[\"model\"],\n",
    "        param_grid=config[\"params\"],\n",
    "        cv=5,  # 5-Fold Cross Validation\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,  # Use all CPU cores\n",
    "        verbose=0,  # Keep it quiet\n",
    "    )\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # B. Validation Check\n",
    "    # Get the best version of the model\n",
    "    tuned_model = gs.best_estimator_\n",
    "\n",
    "    # Test on Validation Set\n",
    "    val_pred = tuned_model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    # C. Store Results\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"CV Score (Avg)\": gs.best_score_,\n",
    "            \"Validation Score\": val_acc,\n",
    "            \"Gap\": abs(gs.best_score_ - val_acc),\n",
    "            \"Best Params\": gs.best_params_,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Save the actual model object for later\n",
    "    best_models[name] = tuned_model\n",
    "\n",
    "    print(f\"   -> CV: {gs.best_score_:.2%} | Val: {val_acc:.2%}\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. RESULTS: The Leaderboard\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"-\" * 60)\n",
    "print(\"üèÅ FINAL LEADERBOARD\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "leaderboard = pd.DataFrame(results).sort_values(by=\"Validation Score\", ascending=False)\n",
    "\n",
    "# Pretty print\n",
    "print(leaderboard[[\"Model\", \"CV Score (Avg)\", \"Validation Score\", \"Gap\"]])\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 4. SAVE THE WINNER\n",
    "# -------------------------------------------------------------------------\n",
    "winner_name = leaderboard.iloc[0][\"Model\"]\n",
    "winner_model = best_models[winner_name]\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(winner_model, \"../models/model.pkl\")\n",
    "print(f\"\\nüíæ The Winner ({winner_name}) has been saved to '../models/model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Testing submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Fix Python path so `src` is found\n",
    "# -------------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust this if your notebook is nested deeper\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Sanity check (optional)\n",
    "assert (PROJECT_ROOT / \"src\").exists(), \"src/ folder not found. Check PROJECT_ROOT.\"\n",
    "\n",
    "# -------------------------------\n",
    "# Imports\n",
    "# -------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import load_config\n",
    "\n",
    "# -------------------------------\n",
    "# Load config\n",
    "# -------------------------------\n",
    "config = load_config()\n",
    "\n",
    "# -------------------------------\n",
    "# Load your model predictions\n",
    "# -------------------------------\n",
    "output_path = PROJECT_ROOT / config[\"data\"][\"predictions_path\"]\n",
    "df_new = pd.read_csv(output_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Load raw test data\n",
    "# -------------------------------\n",
    "test_path = PROJECT_ROOT / config[\"data\"][\"test_path\"]\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# -------------------------------\n",
    "# Gender baseline (all females survive)\n",
    "# -------------------------------\n",
    "df_test[\"Gender_Model\"] = df_test[\"Sex\"].apply(lambda x: 1 if x == \"female\" else 0)\n",
    "\n",
    "# -------------------------------\n",
    "# Compare predictions\n",
    "# -------------------------------\n",
    "diff = (df_new[\"Survived\"] != df_test[\"Gender_Model\"]).sum()\n",
    "\n",
    "print(f\"Total Rows: {len(df_new)}\")\n",
    "print(f\"Differences from Gender Baseline: {diff}\")\n",
    "\n",
    "# Optional: percentage difference\n",
    "pct_diff = diff / len(df_new) * 100\n",
    "print(f\"Difference Percentage: {pct_diff:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "califonia_housing_prices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
